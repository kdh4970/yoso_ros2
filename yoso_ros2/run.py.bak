# Copyright (c) Facebook, Inc. and its affiliates.
import argparse
import glob
import multiprocessing as mp
import numpy as np
import os
import tempfile
import time
import warnings
import cv2
import tqdm
import rclpy
from rcl_interfaces.msg import SetParametersResult
import sys
import timeit
from rclpy.node import Node
from cv_bridge import CvBridge,CvBridgeError
from sensor_msgs.msg import Image

from detectron2.config import get_cfg
from detectron2.data.detection_utils import read_image
from detectron2.utils.logger import setup_logger

from demo.predictor import VisualizationDemo
from demo.config import add_yoso_config
from projects.YOSO.yoso.segmentator import YOSO

import yoso_ros2_msgs.msg as yoso_msgs

# constants
WINDOW_NAME = "COCO detections"

IMAGE_HEIGHT = 360  #720
IMAGE_WIDTH = 640 #1280

CALLBACK_DEBUG = False

class YosoNode(Node):

    def __init__(self):
        super().__init__("yoso_node")
        self.image_topic0 = "/azure_kinect/master/rgb/image_raw"
        self.image_topic1 = "/azure_kinect/sub1/rgb/image_raw"
        self.image_topic2 = "/azure_kinect/sub2/rgb/image_raw"
        self.image_sub0 = self.create_subscription(Image, self.image_topic0, self.image_callback0, 10)
        # self.image_sub1 = self.create_subscription(Image, self.image_topic1, self.image_callback1, 10)
        # self.image_sub2 = self.create_subscription(Image, self.image_topic2, self.image_callback2, 10)
        self.seg_pub0 = self.create_publisher(yoso_msgs.Segmentation, "/yoso_node/master", 10)
        self.seg_pub1 = self.create_publisher(yoso_msgs.Segmentation, "/yoso_node/sub1", 10)
        self.seg_pub2 = self.create_publisher(yoso_msgs.Segmentation, "/yoso_node/sub2", 10)
        self.input_image0 = None
        self.input_image1 = None
        self.input_image2 = None
        self.bridge = CvBridge()
        self.demo = None


    def getcfg(self,cfg):
        self.demo = VisualizationDemo(cfg, parallel=False)
        # self.demo1 = VisualizationDemo(cfg, parallel=False)
        # self.demo2 = VisualizationDemo(cfg, parallel=False)

    def image_callback0(self, msg):
        try :
            # start_time = timeit.default_timer()
            
            self.input_image0 = cv2.resize(self.bridge.imgmsg_to_cv2(msg, "bgr8"), (int(IMAGE_WIDTH),int(IMAGE_HEIGHT)))# 1280 720
            if CALLBACK_DEBUG: print("image callback0"); print("running time : ", 1000 * (end_time-start_time)); print("FPS : ", 1/(end_time-start_time))
            result_frame, self.result_panoptic_seg0, self.segments_info0 = self.demo.run_on_azure(self.input_image0)
            self.publish_seg_result(0,msg.header)
            # self.debug_panoptic()

            # end_time = timeit.default_timer()
            # FPS = 1./(end_time - start_time)
            # cv2.putText(result_frame, "FPS : {:.1f}".format(FPS), (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.imshow("cam 0", result_frame)
            cv2.waitKey(1)
        except CvBridgeError as e:
            print(e)
    def image_callback1(self, msg):
        try :
            # start_time = timeit.default_timer()
            self.input_image1 = cv2.resize(self.bridge.imgmsg_to_cv2(msg, "bgr8"), (int(IMAGE_WIDTH),int(IMAGE_HEIGHT)))# 1280 720
            if CALLBACK_DEBUG: print("image callback1"); print("running time : ", 1000 * (end_time-start_time)); print("FPS : ", 1/(end_time-start_time))
            result_frame, self.result_panoptic_seg1, self.segments_info1 = self.demo.run_on_azure(self.input_image1)
            # self.publish_seg_result(1,msg.header)

            # end_time = timeit.default_timer()
            # FPS = 1./(end_time - start_time)
            # cv2.putText(result_frame, "FPS : {:.1f}".format(FPS), (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.imshow("cam 1", result_frame)
            cv2.waitKey(1)
        except CvBridgeError as e:
            print(e)
    def image_callback2(self, msg):
        try :
            # start_time = timeit.default_timer()
            self.input_image2 = cv2.resize(self.bridge.imgmsg_to_cv2(msg, "bgr8"), (int(IMAGE_WIDTH),int(IMAGE_HEIGHT)))# 1280 720
            if CALLBACK_DEBUG: print("image callback2"); print("running time : ", 1000 * (end_time-start_time)); print("FPS : ", 1/(end_time-start_time))
            result_frame, self.result_panoptic_seg2, self.segments_info2  = self.demo.run_on_azure(self.input_image2)
            # self.publish_seg_result(2,msg.header)

            # end_time = timeit.default_timer()
            # FPS = 1./(end_time - start_time)
            # cv2.putText(result_frame, "FPS : {:.1f}".format(FPS), (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.imshow("cam 2", result_frame)
            cv2.waitKey(1)
        except CvBridgeError as e:
            print(e)

    def publish_seg_result(self,camnum,header):
        start_time = timeit.default_timer()
        if camnum == 0: temp = self.result_panoptic_seg0.tolist()
        elif camnum == 1: temp = self.result_panoptic_seg1.tolist()
        elif camnum == 2: temp = self.result_panoptic_seg2.tolist() # convert tensor to list
        else: print("invalid cam number!"); return
        checkpoint = timeit.default_timer()

        Seg_pub = yoso_msgs.Segmentation()
        for y in range(IMAGE_HEIGHT):
            for x in range(IMAGE_WIDTH): 
                pixel_temp = yoso_msgs.Pixel()
                pixel_temp.pixel_id = y*IMAGE_WIDTH + x
                pixel_temp.seg_id = temp[y][x]
                for index in range(len(self.segments_info0)): # get pixel's seg info
                    if pixel_temp.pixel_id == self.segments_info0[index]['id']:
                        pixel_temp.isthing = self.segments_info0[index]['isthing']
                        pixel_temp.category_id = self.segments_info0[index]['category_id']
                Seg_pub.data.append(pixel_temp)
        checkpoint2 = timeit.default_timer()
        Seg_pub.header = header
        
        if camnum==0: self.seg_pub0.publish(Seg_pub)
        elif camnum==1: self.seg_pub1.publish(Seg_pub)
        elif camnum==2: self.seg_pub2.publish(Seg_pub)
        end_time = timeit.default_timer()
        print("tensor to list : ", 1000 * (checkpoint-start_time))
        print("msg gen time : ", 1000 * (checkpoint2-checkpoint))
        print("msg pub time : ", 1000 * (end_time-checkpoint2))

    def debug_panoptic(self):
        temp = self.result_panoptic_seg0.tolist() # convert tensor to list
        print("!!START===============================")
        # print(temp[0][0]) # pixel's seg id
        print(temp[0]); print(len(temp[0]))
        print(self.segments_info0)
        print(self.segments_info0[0]['id'])
        print(len(self.segments_info0))
        # print(self.result_panoptic_seg0.size())
        print("!!END===============================")

    # def publish_result(self):
    #     cv2.Mat result0 = self.demo.run_on_azure(self.input_image0)

    #     try:
    #         self.image_pub0.publish(self.bridge.cv2_to_imgmsg(result0, "bgr8"))
    #         self.image_pub1.publish(self.bridge.cv2_to_imgmsg(result1, "bgr8"))
    #         self.image_pub2.publish(self.bridge.cv2_to_imgmsg(result2, "bgr8"))
    #     except CvBridgeError as e:
    #         print(e)

def test_opencv_video_format(codec, file_ext):
    with tempfile.TemporaryDirectory(prefix="video_format_test") as dir:
        filename = os.path.join(dir, "test_file" + file_ext)
        writer = cv2.VideoWriter(
            filename=filename,
            fourcc=cv2.VideoWriter_fourcc(*codec),
            fps=float(30),
            frameSize=(10, 10),
            isColor=True,
        )
        [writer.write(np.zeros((10, 10, 3), np.uint8)) for _ in range(30)]
        writer.release()
        if os.path.isfile(filename):
            return True
        return False


def setup_cfg(args):
    # load config from file and command-line arguments
    cfg = get_cfg()
    add_yoso_config(cfg)
    # To use demo for Panoptic-DeepLab, please uncomment the following two lines.
    # from detectron2.projects.panoptic_deeplab import add_panoptic_deeplab_config  # noqa
    # add_panoptic_deeplab_config(cfg)
    cfg.merge_from_file(args.config_file)
    cfg.merge_from_list(args.opts)
    # Set score_threshold for builtin models
    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold
    cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = args.confidence_threshold
    cfg.MODEL.YOSO.TEST.OVERLAP_THRESHOLD = args.overlap_threshold
    cfg.MODEL.YOSO.TEST.OBJECT_MASK_THRESHOLD = args.confidence_threshold
    cfg.freeze()
    return cfg

def get_parser():
    parser = argparse.ArgumentParser(description="Detectron2 demo for builtin configs")
    parser.add_argument(
        "--config-file",
        default="configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml",
        metavar="FILE",
        help="path to config file",
    )
    parser.add_argument("--webcam", action="store_true", help="Take inputs from webcam.")
    parser.add_argument("--azure", action="store_true", help="Take inputs from azure kinect.")
    parser.add_argument("--video-input", help="Path to video file.")
    parser.add_argument(
        "--input",
        nargs="+",
        help="A list of space separated input images; "
        "or a single glob pattern such as 'directory/*.jpg'",
    )
    parser.add_argument(
        "--output",
        help="A file or directory to save output visualizations. "
        "If not given, will show output in an OpenCV window.",
    )
    parser.add_argument(
        "--overlap-threshold",
        type=float,
        default=0.98,
        help="overlap threshold",
    )
    parser.add_argument(
        "--confidence-threshold",
        type=float,
        default=0.8,
        help="Minimum score for instance predictions to be shown",
    )
    parser.add_argument(
        "--opts",
        help="Modify config options using the command-line 'KEY VALUE' pairs",
        default=[],
        nargs=argparse.REMAINDER,
    )
    
    return parser

def main(args=sys.argv[1:]):
    rclpy.init()
    node=YosoNode()
    print("ROS2 Node started!")
    # rclpy.spin(node)
    
    mp.set_start_method("spawn", force=True)
    args = get_parser().parse_args()
    setup_logger(name="fvcore")
    logger = setup_logger()
    logger.info("Arguments: " + str(args))

    cfg = setup_cfg(args)
    node.getcfg(cfg)
    


    # demo = VisualizationDemo(cfg, parallel=False)

    
    if args.azure:
        rclpy.spin(node)
        # rclpy.spin_once(node, timeout_sec=0.1)
        # for vis in demo.run_on_azure(node):
        #     cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)
        #     cv2.imshow(WINDOW_NAME, vis)
        #     if cv2.waitKey(1) == 27:
        #         break  # esc to quit
        # cv2.destroyAllWindows()
        rclpy.shutdown()






if __name__ == "__main__":
    main()